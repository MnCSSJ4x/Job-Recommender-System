{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModel\nimport torch\nimport pandas as pd\ntokenizer = AutoTokenizer.from_pretrained(\"MohammedDhiyaEddine/job-skill-sentence-transformer-tsdae\")\nmodel = AutoModel.from_pretrained(\"MohammedDhiyaEddine/job-skill-sentence-transformer-tsdae\").to('cuda')","metadata":{"execution":{"iopub.status.busy":"2023-04-20T14:13:35.687754Z","iopub.execute_input":"2023-04-20T14:13:35.688281Z","iopub.status.idle":"2023-04-20T14:13:40.949188Z","shell.execute_reply.started":"2023-04-20T14:13:35.688230Z","shell.execute_reply":"2023-04-20T14:13:40.947657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df=pd.read_csv('/kaggle/input/job-recommendation-case-study/jobs.tsv', sep='\\t')\ndf = pd.read_csv('/kaggle/input/job-recommendation-case-study/jobs.tsv',sep = '\\t',usecols=range(3,4)).astype(str)#.head(100)\ndf['Cleaned_Description'] = ''\ndf.head()\ndf\n# del df","metadata":{"execution":{"iopub.status.busy":"2023-04-17T05:50:27.028391Z","iopub.execute_input":"2023-04-17T05:50:27.028937Z","iopub.status.idle":"2023-04-17T05:51:52.523041Z","shell.execute_reply.started":"2023-04-17T05:50:27.028898Z","shell.execute_reply":"2023-04-17T05:51:52.521877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nfrom bs4 import BeautifulSoup\ndef cleanResume(resumeText):\n    soup=BeautifulSoup(resumeText,\"html.parser\")\n    resumeText=soup.get_text()\n    resumeText = re.sub('http\\S+\\s*', ' ', resumeText)  # remove URLs\n    resumeText = re.sub('RT|cc', ' ', resumeText)  # remove RT and cc\n    resumeText = re.sub('#\\S+', '', resumeText)  # remove hashtags\n    resumeText = re.sub('@\\S+', '  ', resumeText)  # remove mentions\n    resumeText = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', resumeText)  # remove punctuations\n    resumeText = re.sub(r'[^\\x00-\\x7f]',r' ', resumeText) \n    resumeText = re.sub('\\s+', ' ', resumeText)  # remove extra whitespace\n    return resumeText\n    \ndf['Cleaned_Description'] = df.Description.apply(lambda x: cleanResume(x))\ndf\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Source'] = 'KaggleManda'\ndf.drop([\"Description\"],inplace=True,axis=1)\n# df = df.rename(columns={'old_name': 'new_name'})\ndf# assign values to new column","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.to_csv(\"KaggleManda.csv\",index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# del df\ndf=pd.read_csv(\"/kaggle/input/scrapeddata/cleaned_jobs.csv\").drop([\"Unnamed: 0\",\"Location\",\"Company\",\"Position\"],axis=1)\n# df=pd.read_csv(\"/kaggle/input/kagglemanda/KaggleManda_embeddings.csv\").drop([\"Source\"],axis=1).dropna()\n# df = df.rename(columns={'Cleaned_Resume': 'Cleaned_Description'})\ndf","metadata":{"execution":{"iopub.status.busy":"2023-04-20T14:53:55.071527Z","iopub.execute_input":"2023-04-20T14:53:55.072598Z","iopub.status.idle":"2023-04-20T14:53:55.136359Z","shell.execute_reply.started":"2023-04-20T14:53:55.072546Z","shell.execute_reply":"2023-04-20T14:53:55.135222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df2.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# merged_df =merged_df = pd.concat([df1, df2])\n# merged_df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# merged_df.to_csv(\"Merged.csv\",index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/merged/Merged.csv\").drop([\"Source\"],axis=1).dropna()\ndf","metadata":{"execution":{"iopub.status.busy":"2023-04-17T04:16:18.596315Z","iopub.execute_input":"2023-04-17T04:16:18.596728Z","iopub.status.idle":"2023-04-17T04:16:23.029210Z","shell.execute_reply.started":"2023-04-17T04:16:18.596690Z","shell.execute_reply":"2023-04-17T04:16:23.027334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.iloc[22603]","metadata":{"execution":{"iopub.status.busy":"2023-04-16T17:09:12.412121Z","iopub.execute_input":"2023-04-16T17:09:12.412583Z","iopub.status.idle":"2023-04-16T17:09:12.420699Z","shell.execute_reply.started":"2023-04-16T17:09:12.412537Z","shell.execute_reply":"2023-04-16T17:09:12.419729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_of_lists =[item for sublist in df.values.tolist() for item in sublist]\nlen(list_of_lists)","metadata":{"execution":{"iopub.status.busy":"2023-04-20T14:54:01.999419Z","iopub.execute_input":"2023-04-20T14:54:01.999884Z","iopub.status.idle":"2023-04-20T14:54:02.010168Z","shell.execute_reply.started":"2023-04-20T14:54:01.999842Z","shell.execute_reply":"2023-04-20T14:54:02.009033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(len(temp))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def mean_pooling(model_output, attention_mask):\n    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\nimport numpy as np\nn=int(df.shape[0])\nmax_len=512\nembeddings=torch.Tensor([]).to('cuda')#(np.zeros((n,df.shape[1],max_len,768)))\nfor i in range(n):\n    sentences =list_of_lists[i]\n    encoded_sentences = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\",max_length=max_len)\n#     encoded_sentences = tokenizer(sentences, return_tensors=\"pt\")\n    encoded_sentences.to('cuda')\n#     print(len(encoded_sentences))\n#     print(i)\n#     print(\"encoded_sentences size=\",len(encoded_sentences[0]),len(encoded_sentences['input_ids']),len(encoded_sentences['input_ids']))\n    with torch.no_grad():\n#         temp=[]\n#         print(model(encoded_sentences['input_ids'], attention_mask=encoded_sentences['attention_mask'])[0])\n        temp=model(**encoded_sentences)\n#     print(model(**encoded_sentences)[0])\n    sentence_embeddings = mean_pooling(temp, encoded_sentences['attention_mask'])\n#         print(temp)\n#     embeddings[i]=temp\n#     embeddings.append(temp)\n    embeddings=torch.cat((embeddings,sentence_embeddings),0)","metadata":{"execution":{"iopub.status.busy":"2023-04-20T14:54:51.540923Z","iopub.execute_input":"2023-04-20T14:54:51.541526Z","iopub.status.idle":"2023-04-20T14:55:02.199188Z","shell.execute_reply.started":"2023-04-20T14:54:51.541488Z","shell.execute_reply":"2023-04-20T14:55:02.198191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(embeddings))\nprint(len(embeddings[0]))\n# print(len(embeddings[0][0]))\n# print(len(embeddings[0][0][0]))","metadata":{"execution":{"iopub.status.busy":"2023-04-20T14:55:02.201085Z","iopub.execute_input":"2023-04-20T14:55:02.201503Z","iopub.status.idle":"2023-04-20T14:55:02.208862Z","shell.execute_reply.started":"2023-04-20T14:55:02.201443Z","shell.execute_reply":"2023-04-20T14:55:02.207728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(embeddings[0][0][0]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embeddings","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\n# Open a file for writing\nwith open('jobEmbeddingArya.pickle', 'wb') as f:\n    # Use pickle to dump the variable to the file\n    pickle.dump(embeddings, f)","metadata":{"execution":{"iopub.status.busy":"2023-04-20T14:55:44.977761Z","iopub.execute_input":"2023-04-20T14:55:44.978342Z","iopub.status.idle":"2023-04-20T14:55:44.988918Z","shell.execute_reply.started":"2023-04-20T14:55:44.978288Z","shell.execute_reply":"2023-04-20T14:55:44.987899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\n\n# Open the pickle file for reading\nwith open('jobEmbeddingArya.pickle', 'rb') as f:\n#     Use pickle to load the variable from the file\n    embeddings = pickle.load(f)\n\n# Print the loaded variable\nprint(embeddings)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-20T14:55:51.157164Z","iopub.execute_input":"2023-04-20T14:55:51.157535Z","iopub.status.idle":"2023-04-20T14:55:51.171154Z","shell.execute_reply.started":"2023-04-20T14:55:51.157501Z","shell.execute_reply":"2023-04-20T14:55:51.169709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# list_of_lists[22603]","metadata":{"execution":{"iopub.status.busy":"2023-04-16T17:07:39.084063Z","iopub.execute_input":"2023-04-16T17:07:39.084583Z","iopub.status.idle":"2023-04-16T17:07:39.094534Z","shell.execute_reply.started":"2023-04-16T17:07:39.084542Z","shell.execute_reply":"2023-04-16T17:07:39.092711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # for my_string in list_of_lists[0]:\n# #         words = my_string.split()\n# # len(words)\n# list1=[]\n# list1.append(list_of_lists[22603].split())\n# # list1.append(list_of_lists[1].split())\n# list1","metadata":{"execution":{"iopub.status.busy":"2023-04-16T17:07:27.526650Z","iopub.execute_input":"2023-04-16T17:07:27.527123Z","iopub.status.idle":"2023-04-16T17:07:27.556771Z","shell.execute_reply.started":"2023-04-16T17:07:27.527084Z","shell.execute_reply":"2023-04-16T17:07:27.555363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list1=[]\nfor i in range(len(list_of_lists)):\n#         words = my_string.split()\n#         print(my_string)\n#     if(i>22600 and i<22700):\n#         print(i)\n    list1.append(list_of_lists[i].split())\nlen(list1)","metadata":{"execution":{"iopub.status.busy":"2023-04-20T14:14:13.980986Z","iopub.execute_input":"2023-04-20T14:14:13.982172Z","iopub.status.idle":"2023-04-20T14:14:14.021924Z","shell.execute_reply.started":"2023-04-20T14:14:13.982085Z","shell.execute_reply":"2023-04-20T14:14:14.020010Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corpus=[item for sublist in list1 for item in sublist]\nlen(corpus)","metadata":{"execution":{"iopub.status.busy":"2023-04-20T14:14:16.527338Z","iopub.execute_input":"2023-04-20T14:14:16.527883Z","iopub.status.idle":"2023-04-20T14:14:16.549839Z","shell.execute_reply.started":"2023-04-20T14:14:16.527838Z","shell.execute_reply":"2023-04-20T14:14:16.547917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\n  \nstop_words = set(stopwords.words('english'))\nfiltered_sentence = [w for w in list1 if not w.lower() in stop_words]\nlen(filtered_sentence)","metadata":{"execution":{"iopub.status.busy":"2023-04-20T14:14:19.741028Z","iopub.status.idle":"2023-04-20T14:14:19.742431Z","shell.execute_reply.started":"2023-04-20T14:14:19.742115Z","shell.execute_reply":"2023-04-20T14:14:19.742157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from gensim.models import Word2Vec\n# my_string = \"This is a string with spaces\"\n# list1=[item for sublist in list1 for item in sublist]\n# Train a Word2Vec model on the sentences\nmodel = Word2Vec(vector_size=300,window=5,min_count=5,workers=-1)\nmodel.build_vocab(corpus)\nmodel.train(corpus,total_examples=model.corpus_count,epochs=5)\nmodel.save(\"word2vecArya.model\")\nmodel = Word2Vec.load(\"word2vecArya.model\")\n# Get the w2v representation of a sentence\n# sentence = ['this', 'is', 'sentence', 'one']\n# w2v_representation = model.wv[list_of_lists[0][0]]\n# for word in list1:\n#   vector = model.wv[word]\n\n# print(vector)","metadata":{"execution":{"iopub.status.busy":"2023-04-20T14:18:47.848845Z","iopub.execute_input":"2023-04-20T14:18:47.849815Z","iopub.status.idle":"2023-04-20T14:18:49.302128Z","shell.execute_reply.started":"2023-04-20T14:18:47.849760Z","shell.execute_reply":"2023-04-20T14:18:49.271577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\ntfidf=TfidfVectorizer(analyzer='word',ngram_range=(1,2),min_df=25,stop_words=\"english\")\ntfidf.fit(df['clean'])\ntfidf_list=dict(zip(tfidf.get_feature_names_out(),list(tfidf.idf_)))\ntfidf_feature=tfidf.get_feature_names_out()","metadata":{"execution":{"iopub.status.busy":"2023-04-20T14:18:49.433018Z","iopub.execute_input":"2023-04-20T14:18:49.433497Z","iopub.status.idle":"2023-04-20T14:18:49.912084Z","shell.execute_reply.started":"2023-04-20T14:18:49.433455Z","shell.execute_reply":"2023-04-20T14:18:49.910476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom tqdm import tqdm\ntfidf_vectors=[]\nline=0\nfor desc in tqdm(corpus):\n    sent_vec=np.zeros(300)\n    weight_sum=0\n    for word in desc:\n        if word in model.wv.key_to_index and word in tfidf_feature:\n            vec=model.wv[word]\n            tf_idf=tfidf_list[word]*(desc.count(word)/len(desc))\n            sent_vec+=(vec*tf_idf)\n            weight_sum+=tf_idf\n        if weight_sum!=0:\n            sent_vec/=weight_sum\n        tfidf_vectors.append(sent_vec)\n        line+=1","metadata":{"execution":{"iopub.status.busy":"2023-04-20T14:18:50.851450Z","iopub.execute_input":"2023-04-20T14:18:50.852897Z","iopub.status.idle":"2023-04-20T14:19:24.340404Z","shell.execute_reply.started":"2023-04-20T14:18:50.852821Z","shell.execute_reply":"2023-04-20T14:19:24.338779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(tfidf_vectors)","metadata":{"execution":{"iopub.status.busy":"2023-04-20T14:18:35.124915Z","iopub.execute_input":"2023-04-20T14:18:35.125348Z","iopub.status.idle":"2023-04-20T14:18:35.134942Z","shell.execute_reply.started":"2023-04-20T14:18:35.125308Z","shell.execute_reply":"2023-04-20T14:18:35.133065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics.pairwise import cosine_similarity\n# cosine_similarity=cosine_similarity(tfidf_vectors,tfidf_vectors)","metadata":{"execution":{"iopub.status.busy":"2023-04-20T15:03:34.200332Z","iopub.execute_input":"2023-04-20T15:03:34.201226Z","iopub.status.idle":"2023-04-20T15:03:34.809837Z","shell.execute_reply.started":"2023-04-20T15:03:34.201175Z","shell.execute_reply":"2023-04-20T15:03:34.808831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dealing with user_embedding","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModel\nimport torch\nimport pandas as pd\ntokenizer = AutoTokenizer.from_pretrained(\"MohammedDhiyaEddine/job-skill-sentence-transformer-tsdae\")\nmodel = AutoModel.from_pretrained(\"MohammedDhiyaEddine/job-skill-sentence-transformer-tsdae\").to('cuda')","metadata":{"execution":{"iopub.status.busy":"2023-04-20T14:41:15.673819Z","iopub.execute_input":"2023-04-20T14:41:15.674190Z","iopub.status.idle":"2023-04-20T14:41:31.184540Z","shell.execute_reply.started":"2023-04-20T14:41:15.674159Z","shell.execute_reply":"2023-04-20T14:41:31.183401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"user_df=pd.read_csv(\"/kaggle/input/userresume/UserResume.csv\").dropna().drop([\"Resume\"],axis=1)\n# user_df[\"Combined\"] = df[\"Category\"].astype(str) + df[\"Cleaned_Resume\"]\nuser_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-20T14:41:31.187627Z","iopub.execute_input":"2023-04-20T14:41:31.188443Z","iopub.status.idle":"2023-04-20T14:41:31.362988Z","shell.execute_reply.started":"2023-04-20T14:41:31.188383Z","shell.execute_reply":"2023-04-20T14:41:31.361802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"user_df[\"Combined\"] = user_df[\"Category\"].astype(str) + user_df[\"Cleaned_Resume\"]\nuser_df=user_df.drop([\"Category\",\"Cleaned_Resume\"],axis=1)\nuser_df","metadata":{"execution":{"iopub.status.busy":"2023-04-20T14:41:31.364561Z","iopub.execute_input":"2023-04-20T14:41:31.364937Z","iopub.status.idle":"2023-04-20T14:41:31.384029Z","shell.execute_reply.started":"2023-04-20T14:41:31.364898Z","shell.execute_reply":"2023-04-20T14:41:31.383121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_of_lists =[item for sublist in user_df.values.tolist() for item in sublist]\nlen(list_of_lists)","metadata":{"execution":{"iopub.status.busy":"2023-04-20T14:41:31.387873Z","iopub.execute_input":"2023-04-20T14:41:31.388151Z","iopub.status.idle":"2023-04-20T14:41:31.396548Z","shell.execute_reply.started":"2023-04-20T14:41:31.388125Z","shell.execute_reply":"2023-04-20T14:41:31.395235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def mean_pooling(model_output, attention_mask):\n    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\nimport numpy as np\nn=int(user_df.shape[0])\nmax_len=512\nembeddings=torch.Tensor([]).to('cuda')#(np.zeros((n,df.shape[1],max_len,768)))\nfor i in range(n):\n    sentences =list_of_lists[i]\n    encoded_sentences = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\",max_length=max_len)\n    encoded_sentences.to('cuda')\n    with torch.no_grad():\n        temp=model(**encoded_sentences)\n    sentence_embeddings = mean_pooling(temp, encoded_sentences['attention_mask'])\n    embeddings=torch.cat((embeddings,sentence_embeddings),0)","metadata":{"execution":{"iopub.status.busy":"2023-04-20T14:41:31.398573Z","iopub.execute_input":"2023-04-20T14:41:31.399429Z","iopub.status.idle":"2023-04-20T14:41:48.678049Z","shell.execute_reply.started":"2023-04-20T14:41:31.399392Z","shell.execute_reply":"2023-04-20T14:41:48.676936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\n# Open a file for writing\nwith open('userEmbeddingArya.pickle', 'wb') as f:\n    # Use pickle to dump the variable to the file\n    pickle.dump(embeddings, f)","metadata":{"execution":{"iopub.status.busy":"2023-04-20T14:42:42.194260Z","iopub.execute_input":"2023-04-20T14:42:42.195198Z","iopub.status.idle":"2023-04-20T14:42:42.206422Z","shell.execute_reply.started":"2023-04-20T14:42:42.195160Z","shell.execute_reply":"2023-04-20T14:42:42.205252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\n\n# Open the pickle file for reading\nwith open('userEmbeddingArya.pickle', 'rb') as f:\n    # Use pickle to load the variable from the file\n    embeddings = pickle.load(f)\n\n# Print the loaded variable\nprint(len(embeddings),len(embeddings[0]))\n","metadata":{"execution":{"iopub.status.busy":"2023-04-20T14:42:43.335866Z","iopub.execute_input":"2023-04-20T14:42:43.336234Z","iopub.status.idle":"2023-04-20T14:42:43.347627Z","shell.execute_reply.started":"2023-04-20T14:42:43.336200Z","shell.execute_reply":"2023-04-20T14:42:43.346390Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Stacking user and job embeddings","metadata":{}},{"cell_type":"code","source":"import pickle\n\n# Open the pickle file for reading\nwith open('/kaggle/input/embeddings/userEmbeddingArya.pickle', 'rb') as f:\n    # Use pickle to load the variable from the file\n    user_embeddings = pickle.load(f)\n\nwith open('/kaggle/input/embeddings/jobEmbeddingArya.pickle', 'rb') as f:\n    # Use pickle to load the variable from the file\n    job_embeddings = pickle.load(f)\n    \n# Print the loaded variable\nprint(len(user_embeddings),len(user_embeddings[0]))\nprint(len(job_embeddings),len(job_embeddings[0]))","metadata":{"execution":{"iopub.status.busy":"2023-04-22T04:57:46.860327Z","iopub.execute_input":"2023-04-22T04:57:46.860597Z","iopub.status.idle":"2023-04-22T04:57:52.974353Z","shell.execute_reply.started":"2023-04-22T04:57:46.860570Z","shell.execute_reply":"2023-04-22T04:57:52.973152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import itertools\nimport pandas as pd\n\n# Create two example tensors\ntensor1 = user_embeddings\ntensor2 = job_embeddings\n\n# Generate all permutations of the two tensors\npermutations = itertools.product(tensor1, tensor2)\n\n# Convert tuples to rows in a DataFrame\nEmbedding_df = pd.DataFrame(permutations, columns=['tensor1', 'tensor2'])\n\n# Display the resulting DataFrame\nprint(Embedding_df.shape)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-22T04:57:52.976843Z","iopub.execute_input":"2023-04-22T04:57:52.977895Z","iopub.status.idle":"2023-04-22T04:57:53.887043Z","shell.execute_reply.started":"2023-04-22T04:57:52.977850Z","shell.execute_reply":"2023-04-22T04:57:53.886026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Embedding_df.shape","metadata":{"execution":{"iopub.status.busy":"2023-04-22T04:57:53.888341Z","iopub.execute_input":"2023-04-22T04:57:53.889003Z","iopub.status.idle":"2023-04-22T04:57:53.897508Z","shell.execute_reply.started":"2023-04-22T04:57:53.888960Z","shell.execute_reply":"2023-04-22T04:57:53.896378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\n# Open a file for writing\nwith open('Embedding_df.pickle', 'wb') as f:\n    # Use pickle to dump the variable to the file\n    pickle.dump(Embedding_df, f)","metadata":{"execution":{"iopub.status.busy":"2023-04-22T04:57:53.900001Z","iopub.execute_input":"2023-04-22T04:57:53.900420Z","iopub.status.idle":"2023-04-22T04:58:09.608889Z","shell.execute_reply.started":"2023-04-22T04:57:53.900385Z","shell.execute_reply":"2023-04-22T04:58:09.607777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import torch.nn.functional as F\n# Embedding_df['similarity'] = F.cosine_similarity(Embedding_df['tensor1'], Embedding_df['tensor2'])","metadata":{"execution":{"iopub.status.busy":"2023-04-22T04:56:50.356894Z","iopub.status.idle":"2023-04-22T04:56:50.357977Z","shell.execute_reply.started":"2023-04-22T04:56:50.357720Z","shell.execute_reply":"2023-04-22T04:56:50.357747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Creating Cosine similairty matrix","metadata":{}},{"cell_type":"code","source":"import pickle\nimport torch\nimport numpy as np\n# Open the pickle file for reading\nwith open('/kaggle/input/embedding-df/Embedding_df.pickle', 'rb') as f:\n    # Use pickle to load the variable from the file\n    Embedding_df = pickle.load(f)\nEmbedding_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-22T16:56:21.272130Z","iopub.execute_input":"2023-04-22T16:56:21.272632Z","iopub.status.idle":"2023-04-22T16:57:01.194839Z","shell.execute_reply.started":"2023-04-22T16:56:21.272587Z","shell.execute_reply":"2023-04-22T16:57:01.192610Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                             tensor1  \\\n0  [tensor(-0.4269, device='cuda:0'), tensor(0.22...   \n1  [tensor(-0.4269, device='cuda:0'), tensor(0.22...   \n2  [tensor(-0.4269, device='cuda:0'), tensor(0.22...   \n3  [tensor(-0.4269, device='cuda:0'), tensor(0.22...   \n4  [tensor(-0.4269, device='cuda:0'), tensor(0.22...   \n\n                                             tensor2  \n0  [tensor(-0.1817, device='cuda:0'), tensor(0.29...  \n1  [tensor(-0.0982, device='cuda:0'), tensor(0.23...  \n2  [tensor(-0.3339, device='cuda:0'), tensor(0.22...  \n3  [tensor(-0.1576, device='cuda:0'), tensor(0.15...  \n4  [tensor(-0.1543, device='cuda:0'), tensor(0.32...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tensor1</th>\n      <th>tensor2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[tensor(-0.4269, device='cuda:0'), tensor(0.22...</td>\n      <td>[tensor(-0.1817, device='cuda:0'), tensor(0.29...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[tensor(-0.4269, device='cuda:0'), tensor(0.22...</td>\n      <td>[tensor(-0.0982, device='cuda:0'), tensor(0.23...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[tensor(-0.4269, device='cuda:0'), tensor(0.22...</td>\n      <td>[tensor(-0.3339, device='cuda:0'), tensor(0.22...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[tensor(-0.4269, device='cuda:0'), tensor(0.22...</td>\n      <td>[tensor(-0.1576, device='cuda:0'), tensor(0.15...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[tensor(-0.4269, device='cuda:0'), tensor(0.22...</td>\n      <td>[tensor(-0.1543, device='cuda:0'), tensor(0.32...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import torch.nn.functional as F\nEmbedding_df['cosine_similarity']=np.zeros((Embedding_df.shape[0]))\n\nfor i in range(Embedding_df.shape[0]):\n    tensor1 = Embedding_df.iloc[i]['tensor1']\n    tensor2 = Embedding_df.iloc[i]['tensor2']\n# compute the cosine similarity between the two tensors\n    cosine_similarity_value = F.cosine_similarity(tensor1.unsqueeze(0), tensor2.unsqueeze(0)).item()\n    Embedding_df['cosine_similarity']=cosine_similarity_value\nEmbedding_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-22T16:59:24.064093Z","iopub.execute_input":"2023-04-22T16:59:24.064801Z","iopub.status.idle":"2023-04-22T17:18:27.528998Z","shell.execute_reply.started":"2023-04-22T16:59:24.064757Z","shell.execute_reply":"2023-04-22T17:18:27.527701Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                             tensor1  \\\n0  [tensor(-0.4269, device='cuda:0'), tensor(0.22...   \n1  [tensor(-0.4269, device='cuda:0'), tensor(0.22...   \n2  [tensor(-0.4269, device='cuda:0'), tensor(0.22...   \n3  [tensor(-0.4269, device='cuda:0'), tensor(0.22...   \n4  [tensor(-0.4269, device='cuda:0'), tensor(0.22...   \n\n                                             tensor2  cosine_similarity  \n0  [tensor(-0.1817, device='cuda:0'), tensor(0.29...           0.768445  \n1  [tensor(-0.0982, device='cuda:0'), tensor(0.23...           0.768445  \n2  [tensor(-0.3339, device='cuda:0'), tensor(0.22...           0.768445  \n3  [tensor(-0.1576, device='cuda:0'), tensor(0.15...           0.768445  \n4  [tensor(-0.1543, device='cuda:0'), tensor(0.32...           0.768445  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tensor1</th>\n      <th>tensor2</th>\n      <th>cosine_similarity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[tensor(-0.4269, device='cuda:0'), tensor(0.22...</td>\n      <td>[tensor(-0.1817, device='cuda:0'), tensor(0.29...</td>\n      <td>0.768445</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[tensor(-0.4269, device='cuda:0'), tensor(0.22...</td>\n      <td>[tensor(-0.0982, device='cuda:0'), tensor(0.23...</td>\n      <td>0.768445</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[tensor(-0.4269, device='cuda:0'), tensor(0.22...</td>\n      <td>[tensor(-0.3339, device='cuda:0'), tensor(0.22...</td>\n      <td>0.768445</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[tensor(-0.4269, device='cuda:0'), tensor(0.22...</td>\n      <td>[tensor(-0.1576, device='cuda:0'), tensor(0.15...</td>\n      <td>0.768445</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[tensor(-0.4269, device='cuda:0'), tensor(0.22...</td>\n      <td>[tensor(-0.1543, device='cuda:0'), tensor(0.32...</td>\n      <td>0.768445</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import pickle\n# Open a file for writing\nwith open('Cosine.pickle', 'wb') as f:\n    # Use pickle to dump the variable to the file\n    pickle.dump(Embedding_df, f)","metadata":{"execution":{"iopub.status.busy":"2023-04-22T17:18:27.531363Z","iopub.execute_input":"2023-04-22T17:18:27.531781Z","iopub.status.idle":"2023-04-22T17:18:49.567025Z","shell.execute_reply.started":"2023-04-22T17:18:27.531742Z","shell.execute_reply":"2023-04-22T17:18:49.565826Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"\nimport pickle\n\n# Open the pickle file for reading\nwith open('Cosine.pickle', 'rb') as f:\n    # Use pickle to load the variable from the file\n    Embedding_df = pickle.load(f)\nEmbedding_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-22T17:26:17.070304Z","iopub.execute_input":"2023-04-22T17:26:17.070935Z","iopub.status.idle":"2023-04-22T17:26:17.124247Z","shell.execute_reply.started":"2023-04-22T17:26:17.070721Z","shell.execute_reply":"2023-04-22T17:26:17.119453Z"},"trusted":true},"execution_count":20,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/621831486.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cosine.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Use pickle to load the variable from the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mEmbedding_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mEmbedding_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/storage.py\u001b[0m in \u001b[0;36m_load_from_bytes\u001b[0;34m(b)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_load_from_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUNSAFE_MESSAGE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m         typed_storage._storage._set_from_file(\n\u001b[1;32m   1021\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_should_read_directly\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m             torch._utils._element_size(typed_storage.dtype))\n\u001b[0m\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m             \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: invalid argument\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."],"ename":"RuntimeError","evalue":"CUDA error: invalid argument\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.","output_type":"error"}]},{"cell_type":"code","source":"\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, TensorDataset\nimport pandas as pd\nimport pickle","metadata":{"execution":{"iopub.status.busy":"2023-04-22T17:24:44.731546Z","iopub.status.idle":"2023-04-22T17:24:44.732789Z","shell.execute_reply.started":"2023-04-22T17:24:44.732487Z","shell.execute_reply":"2023-04-22T17:24:44.732516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.fc1 = nn.Linear(768*2, 512)\n        # nn.relu()\n        self.fc2 = nn.Linear(512, 256)\n        # nn.relu()\n        self.fc3 = nn.Linear(256, 128)\n        # nn.relu()\n        self.fc4 = nn.Linear(128, 1)\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = F.relu(x)\n        x = self.fc2(x)\n        x = F.relu(x)\n        x = self.fc3(x)\n        x = F.relu(x)\n        x = self.fc4(x)\n        return x\nmodel = Model().cuda()\n# Define the loss function and optimizer\ncriterion = nn.MSELoss()\noptimizer = optim.SGD(net.parameters(), lr=0.01)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-22T17:24:44.734285Z","iopub.status.idle":"2023-04-22T17:24:44.735215Z","shell.execute_reply.started":"2023-04-22T17:24:44.734960Z","shell.execute_reply":"2023-04-22T17:24:44.734987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = torch.tensor(df['cosine_similarity'].values).to(\"cuda\")\n\n\nfor epoch in range(10):\n    for i in range(len(Embedding_df)/10000):\n        optimizer.zero_grad()\n        output = model(torch.cat((Embedding_df['tensor1'].values, Embedding_df['tensor2'].values), dim=1))\n        loss = criterion(output, y)\n        loss.backward()\n        optimizer.step()\n\n    if epoch % 1 == 0:\n        print('Epoch [%d/%d], Loss: %.4f' % (epoch+1, 100, loss.item()))","metadata":{"execution":{"iopub.status.busy":"2023-04-22T17:24:44.737821Z","iopub.status.idle":"2023-04-22T17:24:44.738697Z","shell.execute_reply.started":"2023-04-22T17:24:44.738408Z","shell.execute_reply":"2023-04-22T17:24:44.738436Z"},"trusted":true},"execution_count":null,"outputs":[]}]}